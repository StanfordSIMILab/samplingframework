{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FVI Clustering\n",
    "\n",
    "This notebook filters frames based on FVI scores, creates embeddings for the selected frames, and clusters the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "\n",
    "# Add the path to the scripts directory\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "from fvi_computation import compute_fvi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load FVI Scores\n",
    "\n",
    "Load the FVI scores from the `fvi_scores.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fvi_scores(directory):\n",
    "    fvi_scores = {}\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file == 'fvi_scores.json':\n",
    "                filepath = os.path.join(root, file)\n",
    "                with open(filepath, 'r') as f:\n",
    "                    scores = json.load(f)\n",
    "                    fvi_scores[root] = scores\n",
    "    return fvi_scores\n",
    "\n",
    "fvi_scores = load_fvi_scores('../output/ground_truth')\n",
    "fvi_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Frames\n",
    "\n",
    "Filter frames with FVI scores above a certain threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 90  # Set your threshold here\n",
    "selected_frames = []\n",
    "\n",
    "for directory, scores in fvi_scores.items():\n",
    "    for i, score in enumerate(scores):\n",
    "        if score > threshold:\n",
    "            frame_path = os.path.join(directory, f'{i+1:04d}.json')\n",
    "            selected_frames.append(frame_path)\n",
    "\n",
    "selected_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Embeddings\n",
    "\n",
    "Use a pre-trained ResNet model from PyTorch to create embeddings for the selected frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.densenet121(pretrained=True)\n",
    "model = nn.Sequential(*list(model.children())[:-1])  # Remove the classification layer\n",
    "model.eval()\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def get_embedding(img_path):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_tensor = preprocess(img)\n",
    "    img_tensor = img_tensor.unsqueeze(0)  # Add batch dimension\n",
    "    with torch.no_grad():\n",
    "        embedding = model(img_tensor)\n",
    "    return embedding.squeeze().numpy()\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for frame_path in selected_frames:\n",
    "    img_path = frame_path.replace('.json', '.jpg')  # Assuming images are in the same directory with .jpg extension I need the image files as well to create embeddings\n",
    "    embedding = get_embedding(img_path)\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "embeddings = np.array(embeddings)\n",
    "embeddings.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Embeddings\n",
    "\n",
    "Apply KMeans clustering to the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters = 4  # Set the number of clusters\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Clusters\n",
    "\n",
    "Use PCA to reduce the dimensionality of the embeddings and visualize the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(n_clusters):\n",
    "    cluster_points = reduced_embeddings[clusters == i]\n",
    "    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f'Cluster {i}')\n",
    "plt.legend()\n",
    "plt.title('Clusters of Frames')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.show()\n",
    "\n",
    "# Visualize Clusters with FiftyOne\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "# Create a FiftyOne dataset for the clustered samples\n",
    "clustered_dataset = fo.Dataset(name=\"clustered_dataset\")\n",
    "\n",
    "# Add samples with cluster labels to the new dataset\n",
    "for sample in samples:\n",
    "    clustered_sample = fo.Sample(filepath=sample.filepath, cluster=sample.cluster)\n",
    "    clustered_dataset.add_sample(clustered_sample)\n",
    "\n",
    "# Launch the FiftyOne app to visualize the clustered datase Python version 3.11 is not yet supported by FiftyOne. Please use a different version of Python. Used 3.10 to install\n",
    "session = fo.launch_app(clustered_dataset)\n",
    "\n",
    "# Display the clusters in the FiftyOne app\n",
    "session.view = clustered_dataset.filter_labels(\"cluster\", fo.ViewField(\"cluster\").is_in([0, 1, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
